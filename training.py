"""
This is a script for traing a resnet-based VAE on the MNIST training data.

run with args {img_directory} {dataset} {latent_dim} {num_layers} {num_blocks} {beta}
"""
import os
import sys

from matplotlib import pyplot as plt

import torch
from torch import nn
import torch.nn.functional as F

import torchvision
from torchvision import datasets, transforms
from torchvision.transforms import v2

from VAE_model import VAE_loss_binary, VAE_loss_norm, ConvVAE, ResVAE, LinearVAE, ShallowConvVAE
import vision_datasets

def tensor_save(x, path, name, dataset_name, model_name):
    img = x.data.cpu().permute(1, 2, 0).numpy()
    plt.imshow(img)
    fname = os.path.join(path, name + ".png")
    plt.title(f"{dataset_name} samples generated by {model_name}")
    plt.savefig(fname)

def get_dataset(dataset_name: str):
    match dataset_name:
        case "MNIST":
            return vision_datasets.get_MNIST()
        case "CIFAR10":
            return vision_datasets.get_CIFAR10()
        case "CelebA":
            return vision_datasets.get_CelebA()
        case _:
            raise Exception("You must enter a valid dataset")

def get_model(model_name: str):
    match model_name:
        case "ConvVAE":
            return ConvVAE
        case "ResVAE":
            return ResVAE
        case "LinearVAE":
            return LinearVAE
        case "ShallowConvVAE":
            return ShallowConvVAE
        case _:
            raise Exception("You must enter a valid model")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        path = sys.argv[1]
    else:
        raise Exception("Please enter a path for saving the plots.")
    if len(sys.argv) > 2:
        dataset_name = sys.argv[2]
        data, input_size, input_channels = get_dataset(dataset_name)
    else:
        raise Exception("Please enter the name of the dataset")
    if len(sys.argv) > 3:
        model_name = sys.argv[3]
        model = get_model(model_name)
    else:
        raise Exception("Please enter the name of the model")

    loader = torch.utils.data.DataLoader(data, batch_size=32, shuffle=True)

    latent_dim = 50
    num_layers = 15
    blocks = 5
    beta = 0.002
    epochs = 10

    if len(sys.argv) > 4:
        latent_dim = int(sys.argv[4])

        if len(sys.argv) > 5:
            beta = float(sys.argv[5])

            if len(sys.argv) > 6:
                epochs = int(sys.argv[6])

                if len(sys.argv) > 7:
                    num_layers = int(sys.argv[7])

                    if len(sys.argv) > 8:
                        blocks = int(sys.argv[8])

    print(f"Training {dataset_name} using {model_name}")
    print(f"laten_dim:{latent_dim}, beta:{beta}")


    device = torch.device("cuda: 0" if torch.cuda.is_available() else "cpu")
    model = model(device=device,
                    input_size=input_size,
                    input_channels=input_channels,
                    latent_dim=latent_dim,
                    num_layers=num_layers,
                    blocks=blocks)

    print(f"Paramter count: {sum(map(torch.numel, model.parameters()))}")

    model.to(device)

    if(model_name == "ShallowConvVAE"):
        print("Using RMSProp")
        opt = torch.optim.RMSprop(model.parameters(), lr=1e-3)
    else:
        print("Using Adam")
        opt = torch.optim.Adam(model.parameters(), lr=1e-3)

    if(dataset_name == "MNIST"):
        print("Using binary loss function")
        loss = VAE_loss_binary
    else:
        loss = VAE_loss_norm

    train_rl = []
    train_kl = []
    train_loss = []

    for epoch in range(epochs):
        model.train()
        train_rl.append(0)
        train_kl.append(0)
        train_loss.append(0)
        for i, x in enumerate(loader):
            if len(x) == 2:
                x = x[0]
            x = x.to(device)
            opt.zero_grad()

            mu, logvar, out = model(x)
            rl, kl, l = loss(x, out, mu, logvar, beta)

            train_rl[-1] += rl.item()
            train_kl[-1] += kl.item()
            train_loss[-1] += l.item()

            l.backward()
            opt.step()
        with torch.no_grad():
            data = model.generate(36).cpu().detach()
            grid_img = torchvision.utils.make_grid(data, nrow=6, normalize=True)
            tensor_save(grid_img, path=path, name=f"{dataset_name}_{model_name}_epoch{epoch}",
                        dataset_name=dataset_name, model_name=model_name)

        train_kl[-1] /= len(loader)
        train_rl[-1] /= len(loader)
        train_loss[-1] /= len(loader)

losses = [train_kl, train_rl, train_loss]
losses_names = ["KL", "Reconstruction", "Loss"]

for loss, name in zip(losses, losses_names):
    fig, ax = plt.subplots()
    ax.plot(loss)
    ax.set_xlabel("Epoch")
    ax.set_ylabel("Loss")
    ax.set_title(name)
    fname = f"{name}_{dataset_name}_{model_name}.png"
    fname = os.path.join(path, fname)
    plt.savefig(fname)
