"""
This is a script for traing a resnet-based VAE on the MNIST training data.

run with args {img_directory} {dataset} {latent_dim} {num_layers} {num_blocks} {beta}
"""
import os
import sys
import types

from matplotlib import pyplot as plt

import torch
from torch import nn
import torch.nn.functional as F
from torch.utils.data import Dataloader, dataloader

import torchvision
from torchvision import datasets, transforms
from torchvision.transforms import v2

from VAE_model import VAE_loss_binary, VAE_loss_norm, ConvVAE, ResVAE, LinearVAE, ShallowConvVAE
import vision_datasets

def tensor_save(x, path, name, dataset_name, model_name):
    img = x.data.cpu().permute(1, 2, 0).numpy()
    plt.imshow(img)
    fname = os.path.join(path, name + ".png")
    plt.title(f"{dataset_name} samples generated by {model_name}")
    plt.savefig(fname)

def save_losses(losses, losses_names):
    for loss, name in zip(losses, losses_names):
        fig, ax = plt.subplots()
        ax.plot(loss)
        ax.set_xlabel("Epoch")
        ax.set_ylabel("Loss")
        ax.set_title(name)
        fname = f"{name}_{dataset_name}_{model_name}.png"
        fname = os.path.join(path, fname)
        plt.savefig(fname)

def get_dataset(dataset_name: str):
    match dataset_name:
        case "MNIST":
            return vision_datasets.get_MNIST()
        case "CIFAR10":
            return vision_datasets.get_CIFAR10()
        case "CelebA":
            return vision_datasets.get_CelebA()
        case _:
            raise Exception("You must enter a valid dataset")

def get_model(model_name: str):
    match model_name:
        case "ConvVAE":
            return ConvVAE
        case "ResVAE":
            return ResVAE
        case "LinearVAE":
            return LinearVAE
        case "ShallowConvVAE":
            return ShallowConvVAE
        case _:
            raise Exception("You must enter a valid model")
        
def get_losses(model: nn.Module,
            loader: dataloader.DataLoader,
            batches: int,
            loss: types.FunctionType):
    total_loss = 0.0
    total_kl = 0.0
    total_rl = 0.0
    num_batches = 0
    data_iter = iter(loader)
    
    for _ in range(batches):
        try:
            x = next(data_iter)
        except StopIteration:
            break
        
        if len(x) == 2:
            x = x[0]
        with torch.no_grad():
            mu, logvar, out = model(x)
            rl, kl, l = loss(x, out, mu, logvar, beta)

        total_loss += l.item()
        total_kl += kl.item()
        total_rl += rl.item()
        num_batches += 1

    total_loss /= num_batches
    total_kl /= num_batches
    total_rl /= num_batches

    result = {}
    result['loss'] = total_loss
    result['kl'] = total_kl
    result['rl'] = total_rl
    return result

if __name__ == "__main__":
    if len(sys.argv) > 1:
        path = sys.argv[1]
    else:
        raise Exception("Please enter a path for saving the plots.")
    if len(sys.argv) > 2:
        dataset_name = sys.argv[2]
        dataset_dict = get_dataset(dataset_name)
        input_size = dataset_dict['input_size']
        input_channels = dataset_dict['input_channels']
        train_data = dataset_dict['train']
        test_data = dataset_dict['test']
    else:
        raise Exception("Please enter the name of the dataset")
    if len(sys.argv) > 3:
        model_name = sys.argv[3]
        model = get_model(model_name)
    else:
        raise Exception("Please enter the name of the model")

    batch_size = 32
    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)

    latent_dim = 50
    num_layers = 15
    blocks = 5
    beta = 0.002
    epochs = 10

    if len(sys.argv) > 4:
        latent_dim = int(sys.argv[4])

        if len(sys.argv) > 5:
            beta = float(sys.argv[5])

            if len(sys.argv) > 6:
                epochs = int(sys.argv[6])

                if len(sys.argv) > 7:
                    num_layers = int(sys.argv[7])

                    if len(sys.argv) > 8:
                        blocks = int(sys.argv[8])

    print(f"Training {dataset_name} using {model_name}")
    print(f"laten_dim:{latent_dim}, beta:{beta}")


    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model = model(device=device,
                    input_size=input_size,
                    input_channels=input_channels,
                    latent_dim=latent_dim,
                    num_layers=num_layers,
                    blocks=blocks)

    print(f"Paramter count: {sum(map(torch.numel, model.parameters()))}")

    model.to(device)

    if(model_name == "ShallowConvVAE"):
        print("Using RMSProp")
        opt = torch.optim.RMSprop(model.parameters(), lr=1e-3)
    else:
        print("Using Adam")
        opt = torch.optim.Adam(model.parameters(), lr=1e-3)

    if(dataset_name == "MNIST"):
        print("Using binary loss function")
        loss = VAE_loss_binary
    else:
        loss = VAE_loss_norm

    train_rl = []
    train_kl = []
    train_loss = []

    val_rl = []
    val_kl = []
    val_loss = []

    for epoch in range(epochs):
        model.train()
        for i, x in enumerate(train_loader):
            if len(x) == 2:
                x = x[0]
            x = x.to(device)
            opt.zero_grad()

            mu, logvar, out = model(x)
            rl, kl, l = loss(x, out, mu, logvar, beta)

            l.backward()
            opt.step()
        with torch.no_grad():
            data = model.generate(36).cpu().detach()
            grid_img = torchvision.utils.make_grid(data, nrow=6, normalize=True)
            tensor_save(grid_img, path=path, name=f"{dataset_name}_{model_name}_epoch{epoch}",
                        dataset_name=dataset_name, model_name=model_name)
        train_losses = get_losses(model=model, loader=train_loader, batches=100, loss=loss)
        val_losses = get_losses(model=model, loader=train_loader, batches=100, loss=loss)

        train_loss.append(train_losses['loss'])
        train_kl.append(train_losses['kl'])
        train_rl.append(train_losses['rl'])

        val_loss.append(val_losses['loss'])
        val_kl.append(val_losses['kl'])
        val_rl.append(val_losses['rl'])

losses = [train_kl, train_rl, train_loss, val_kl, val_rl, val_loss]
losses_names = ["Train KL", "Train Reconstruction", "Train Loss",
                "Validation KL", "Validation Reconstruction", "Validation Loss"]

save_losses(losses=losses, losses_names=losses_names)
